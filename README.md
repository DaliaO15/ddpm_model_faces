# DDPM for Human Face Generation

This project implements a Denoising Diffusion Probabilistic Model (DDPM) to generate realistic human faces from noise. This implementation demonstrates my understanding of modern generative modeling techniques, PyTorch, and deep learning workflows.

## Highlights 
* Implements a DDPM from scratch using PyTorch and Accelerate
* Trained on a unbiased dataset of human faces (FairFace)
* Includes:
  * training and evaluation loops
  * noise scheduling and sampling steps
  * exponential mean average (EMA) for evaluation and sampling 
  * model monitoring with tensorboards
  * Inference with Gradio interface
* Generates diverse and realistic human faces from pure noise
* Modular and extensible codebase for experimentation

## Repository Structure

[//]: # (Comment: I need to rework on this)

. \
├── utils.py              # Helper functions (e.g., early stopping and sampling) \
├── face_generation_main_EMA.py           # Training loop \
├── inference.py          # Sampling logic to generate images \
├── config.py             # Configuration for hyperparameters and paths \
├── environment.yml       # Dependencies \
└── README.md             # Project overview 

## If you want to run the code 

### 1. Clone the repository
```
git clone https://github.com/DaliaO15/ddpm_model_faces.git
cd ddpm_model_faces
```

### 2. Install dependencies

```
conda env create -f environment.yml
```

### 3. Train the model

```
python face_generation_main_EMA.py
```

Considerations:

1. Make sure to change the necessary paths.
2. The training code tracks the model performance while training. Make sure that you configure tensorboard for this so that you can open the tool in your browser. 

<sup>This is an example of how the tensor board would look like:</sup>

![This is an example of how the tensor board would look like](/imgs/tensorboard_exmp.png)

### 4. Generate samples

[//]: # (Comment: add a inference module)

Once you have your model, you can use the weights and configuration to generate samples. In this example, the inference script also opens a Gradio web application to interact with the model in a nicer interface. This is how it would look in the browser:

```
python inference.py
```

<sup>Inference with Gradio interface</sup>

![Inference with Gradio interface](/imgs/gradio_exmp.png)

## Results

The model was trained on FairFAce at 128x128 resolution. Below are samples generated by the trained DDPM:

<sup>Generated faces with the model</sup>

![Generated faces with the model](/imgs/image.webp)

## Future Work

- Train on higher-resolution datasets or implement something to improve the resolution of the images in the training data as well as in the inference images
- Integrate classifier-free guidance for conditional generation
- Experiment with other diffusion model variants like LSD