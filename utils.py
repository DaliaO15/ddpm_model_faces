from datasets import load_dataset
from dataclasses import dataclass
import matplotlib.pyplot as plt
import os
import json
from PIL import Image
import time

# For data processing
from torchvision import transforms
from torchvision.utils import make_grid
import torch

# To track the losses 
from torch.utils.tensorboard import SummaryWriter


@dataclass
class TrainingConfig:
    image_size = 128  # the generated image resolution
    train_batch_size = 32
    eval_batch_size = 16  # how many images to sample during evaluation
    num_epochs = 5
    gradient_accumulation_steps = 1
    learning_rate = 1e-4
    lr_warmup_steps = 500
    save_image_epochs = 5
    save_model_epochs = 30
    mixed_precision = 'fp16'  # `no` for float32, `fp16` for automatic mixed precision
    output_dir = 'ddpm-faces-128'  # the model namy locally and on the HF Hub
    
    early_stopping_patience = 10
    early_stopping_min_delta = 0.0

    push_to_hub = False #True  # whether to upload the saved model to the HF Hub
    hub_private_repo = False
    overwrite_output_dir = True  # overwrite the old model when re-running the notebook
    seed = 0

class EarlyStopping:
    def __init__(self, patience=5, min_delta=0.0):
        self.patience = patience
        self.min_delta = min_delta
        self.best_loss = float("inf")
        self.counter = 0
        self.should_stop = False

    def step(self, current_loss):
        if current_loss < self.best_loss - self.min_delta:
            self.best_loss = current_loss
            self.counter = 0
            return True  # improvement happened
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.should_stop = True
            return False  # no improvement

def transform_examples(examples, image_size):
    """
    Applies preprocessing to a batch of image examples.
    
    Args:
        examples (dict): A dictionary with "image" as a key.
        image_size (int): The size of the images

    Returns:
        dict: A dictionary with transformed "images".
    """
    preprocess_fn = transforms.Compose([
        transforms.Resize((int(image_size * 1.1), int(image_size * 1.1))),
        transforms.RandomCrop(image_size),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5]),
    ])
    
    images = [preprocess_fn(image.convert("RGB")) for image in examples["image"]]
    return {"images": images}

def my_make_grid(images, rows, cols):
    """ 
    Makes a grid of images generated by the trained model
    """
    w, h = images[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    for i, image in enumerate(images):
        grid.paste(image, box=(i%cols*w, i//cols*h))
    return grid

def evaluate(config, epoch, pipeline, run_name):
    # Sample some images from random noise (this is the backward diffusion process).
    # The default pipeline output type is `List[PIL.Image]`
    images = pipeline(
        batch_size = config.eval_batch_size,
        generator=torch.manual_seed(config.seed),
    ).images

    # Make a grid out of the images
    image_grid = my_make_grid(images, rows=4, cols=4)

    # Save the images    
    test_dir = os.path.join(config.output_dir, os.path.join("samples", run_name))
    os.makedirs(test_dir, exist_ok=True)
    image_grid.save(f"{test_dir}/{epoch:04d}.png")